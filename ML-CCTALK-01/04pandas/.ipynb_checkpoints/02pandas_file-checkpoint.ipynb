{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件读取处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1 引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 文件读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01=pd.read_json(\"abcdef03_split.json\",orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-18</th>\n",
       "      <td>-0.244261</td>\n",
       "      <td>-0.659964</td>\n",
       "      <td>-0.803129</td>\n",
       "      <td>0.375711</td>\n",
       "      <td>1.663186</td>\n",
       "      <td>-0.633984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-19</th>\n",
       "      <td>-0.599928</td>\n",
       "      <td>-0.319406</td>\n",
       "      <td>0.567199</td>\n",
       "      <td>-2.330388</td>\n",
       "      <td>0.883012</td>\n",
       "      <td>-0.198178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-20</th>\n",
       "      <td>2.026703</td>\n",
       "      <td>0.752887</td>\n",
       "      <td>-1.591276</td>\n",
       "      <td>-1.094253</td>\n",
       "      <td>0.324209</td>\n",
       "      <td>0.295673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-21</th>\n",
       "      <td>0.036035</td>\n",
       "      <td>0.232062</td>\n",
       "      <td>0.581130</td>\n",
       "      <td>-0.500515</td>\n",
       "      <td>-2.112790</td>\n",
       "      <td>-1.768483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-22</th>\n",
       "      <td>-0.722143</td>\n",
       "      <td>-0.812356</td>\n",
       "      <td>0.407740</td>\n",
       "      <td>0.443017</td>\n",
       "      <td>-1.026598</td>\n",
       "      <td>-0.051102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-23</th>\n",
       "      <td>0.621833</td>\n",
       "      <td>-0.422199</td>\n",
       "      <td>0.189628</td>\n",
       "      <td>-0.598335</td>\n",
       "      <td>0.059643</td>\n",
       "      <td>0.136458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-24</th>\n",
       "      <td>-0.623433</td>\n",
       "      <td>0.741158</td>\n",
       "      <td>0.460051</td>\n",
       "      <td>-0.567886</td>\n",
       "      <td>-0.348610</td>\n",
       "      <td>-1.071626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-25</th>\n",
       "      <td>-1.241214</td>\n",
       "      <td>-0.749104</td>\n",
       "      <td>0.841774</td>\n",
       "      <td>-0.267436</td>\n",
       "      <td>-0.326296</td>\n",
       "      <td>-0.819834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-26</th>\n",
       "      <td>1.804951</td>\n",
       "      <td>-1.462064</td>\n",
       "      <td>0.160139</td>\n",
       "      <td>-1.006510</td>\n",
       "      <td>-0.005313</td>\n",
       "      <td>-1.287751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-27</th>\n",
       "      <td>-2.066398</td>\n",
       "      <td>1.441313</td>\n",
       "      <td>0.556940</td>\n",
       "      <td>-0.027242</td>\n",
       "      <td>-0.655524</td>\n",
       "      <td>-1.176466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D         E         F\n",
       "2016-08-18 -0.244261 -0.659964 -0.803129  0.375711  1.663186 -0.633984\n",
       "2016-08-19 -0.599928 -0.319406  0.567199 -2.330388  0.883012 -0.198178\n",
       "2016-08-20  2.026703  0.752887 -1.591276 -1.094253  0.324209  0.295673\n",
       "2016-08-21  0.036035  0.232062  0.581130 -0.500515 -2.112790 -1.768483\n",
       "2016-08-22 -0.722143 -0.812356  0.407740  0.443017 -1.026598 -0.051102\n",
       "2016-08-23  0.621833 -0.422199  0.189628 -0.598335  0.059643  0.136458\n",
       "2016-08-24 -0.623433  0.741158  0.460051 -0.567886 -0.348610 -1.071626\n",
       "2016-08-25 -1.241214 -0.749104  0.841774 -0.267436 -0.326296 -0.819834\n",
       "2016-08-26  1.804951 -1.462064  0.160139 -1.006510 -0.005313 -1.287751\n",
       "2016-08-27 -2.066398  1.441313  0.556940 -0.027242 -0.655524 -1.176466"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " read_sql_query(sql, con, index_col=None, coerce_float=True, params=None,\n",
      "                parse_dates=None, chunksize=None)\n",
      "\n",
      "Read SQL query into a DataFrame.\n",
      "\n",
      "Returns a DataFrame corresponding to the result set of the query\n",
      "string. Optionally provide an `index_col` parameter to use one of the\n",
      "columns as the index, otherwise default integer index will be used.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "sql : string SQL query or SQLAlchemy Selectable (select or text object)\n",
      "    SQL query to be executed.\n",
      "con : SQLAlchemy connectable(engine/connection), database string URI,\n",
      "    or sqlite3 DBAPI2 connection\n",
      "    Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "    library.\n",
      "    If a DBAPI2 object, only sqlite3 is supported.\n",
      "index_col : string or list of strings, optional, default: None\n",
      "    Column(s) to set as index(MultiIndex).\n",
      "coerce_float : boolean, default True\n",
      "    Attempts to convert values of non-string, non-numeric objects (like\n",
      "    decimal.Decimal) to floating point. Useful for SQL result sets.\n",
      "params : list, tuple or dict, optional, default: None\n",
      "    List of parameters to pass to execute method.  The syntax used\n",
      "    to pass parameters is database driver dependent. Check your\n",
      "    database driver documentation for which of the five syntax styles,\n",
      "    described in PEP 249's paramstyle, is supported.\n",
      "    Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}\n",
      "parse_dates : list or dict, default: None\n",
      "    - List of column names to parse as dates.\n",
      "    - Dict of ``{column_name: format string}`` where format string is\n",
      "      strftime compatible in case of parsing string times, or is one of\n",
      "      (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "    - Dict of ``{column_name: arg dict}``, where the arg dict corresponds\n",
      "      to the keyword arguments of :func:`pandas.to_datetime`\n",
      "      Especially useful with databases without native Datetime support,\n",
      "      such as SQLite.\n",
      "chunksize : int, default None\n",
      "    If specified, return an iterator where `chunksize` is the number of\n",
      "    rows to include in each chunk.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Any datetime values with time zone information parsed via the `parse_dates`\n",
      "parameter will be converted to UTC.\n",
      "\n",
      "See also\n",
      "--------\n",
      "read_sql_table : Read SQL database table into a DataFrame.\n",
      "read_sql\n"
     ]
    }
   ],
   "source": [
    "np.info(pd.read_sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " read_json(path_or_buf=None, orient=None, typ='frame', dtype=True,\n",
      "           convert_axes=True, convert_dates=True, keep_default_dates=True,\n",
      "           numpy=False, precise_float=False, date_unit=None, encoding=None,\n",
      "           lines=False)\n",
      "\n",
      "Convert a JSON string to pandas object\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "path_or_buf : a valid JSON string or file-like, default: None\n",
      "    The string could be a URL. Valid URL schemes include http, ftp, s3, and\n",
      "    file. For file URLs, a host is expected. For instance, a local file\n",
      "    could be ``file://localhost/path/to/table.json``\n",
      "\n",
      "orient : string,\n",
      "    Indication of expected JSON string format.\n",
      "    Compatible JSON strings can be produced by ``to_json()`` with a\n",
      "    corresponding orient value.\n",
      "    The set of possible orients is:\n",
      "\n",
      "    - ``'split'`` : dict like\n",
      "      ``{index -> [index], columns -> [columns], data -> [values]}``\n",
      "    - ``'records'`` : list like\n",
      "      ``[{column -> value}, ... , {column -> value}]``\n",
      "    - ``'index'`` : dict like ``{index -> {column -> value}}``\n",
      "    - ``'columns'`` : dict like ``{column -> {index -> value}}``\n",
      "    - ``'values'`` : just the values array\n",
      "\n",
      "    The allowed and default values depend on the value\n",
      "    of the `typ` parameter.\n",
      "\n",
      "    * when ``typ == 'series'``,\n",
      "\n",
      "      - allowed orients are ``{'split','records','index'}``\n",
      "      - default is ``'index'``\n",
      "      - The Series index must be unique for orient ``'index'``.\n",
      "\n",
      "    * when ``typ == 'frame'``,\n",
      "\n",
      "      - allowed orients are ``{'split','records','index',\n",
      "        'columns','values'}``\n",
      "      - default is ``'columns'``\n",
      "      - The DataFrame index must be unique for orients ``'index'`` and\n",
      "        ``'columns'``.\n",
      "      - The DataFrame columns must be unique for orients ``'index'``,\n",
      "        ``'columns'``, and ``'records'``.\n",
      "\n",
      "typ : type of object to recover (series or frame), default 'frame'\n",
      "dtype : boolean or dict, default True\n",
      "    If True, infer dtypes, if a dict of column to dtype, then use those,\n",
      "    if False, then don't infer dtypes at all, applies only to the data.\n",
      "convert_axes : boolean, default True\n",
      "    Try to convert the axes to the proper dtypes.\n",
      "convert_dates : boolean, default True\n",
      "    List of columns to parse for dates; If True, then try to parse\n",
      "    datelike columns default is True; a column label is datelike if\n",
      "\n",
      "    * it ends with ``'_at'``,\n",
      "\n",
      "    * it ends with ``'_time'``,\n",
      "\n",
      "    * it begins with ``'timestamp'``,\n",
      "\n",
      "    * it is ``'modified'``, or\n",
      "\n",
      "    * it is ``'date'``\n",
      "\n",
      "keep_default_dates : boolean, default True\n",
      "    If parsing dates, then parse the default datelike columns\n",
      "numpy : boolean, default False\n",
      "    Direct decoding to numpy arrays. Supports numeric data only, but\n",
      "    non-numeric column and index labels are supported. Note also that the\n",
      "    JSON ordering MUST be the same for each term if numpy=True.\n",
      "precise_float : boolean, default False\n",
      "    Set to enable usage of higher precision (strtod) function when\n",
      "    decoding string to double values. Default (False) is to use fast but\n",
      "    less precise builtin functionality\n",
      "date_unit : string, default None\n",
      "    The timestamp unit to detect if converting dates. The default behaviour\n",
      "    is to try and detect the correct precision, but if this is not desired\n",
      "    then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,\n",
      "    milliseconds, microseconds or nanoseconds respectively.\n",
      "lines : boolean, default False\n",
      "    Read the file as a json object per line.\n",
      "\n",
      "    .. versionadded:: 0.19.0\n",
      "\n",
      "encoding : str, default is 'utf-8'\n",
      "    The encoding to use to decode py3 bytes.\n",
      "\n",
      "    .. versionadded:: 0.19.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "result : Series or DataFrame, depending on the value of `typ`.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.to_json\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "...                   index=['row 1', 'row 2'],\n",
      "...                   columns=['col 1', 'col 2'])\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'split'`` formatted JSON:\n",
      "\n",
      ">>> df.to_json(orient='split')\n",
      "'{\"columns\":[\"col 1\",\"col 2\"],\n",
      "  \"index\":[\"row 1\",\"row 2\"],\n",
      "  \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      ">>> pd.read_json(_, orient='split')\n",
      "      col 1 col 2\n",
      "row 1     a     b\n",
      "row 2     c     d\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "\n",
      ">>> df.to_json(orient='index')\n",
      "'{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      ">>> pd.read_json(_, orient='index')\n",
      "      col 1 col 2\n",
      "row 1     a     b\n",
      "row 2     c     d\n",
      "\n",
      "Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "Note that index labels are not preserved with this encoding.\n",
      "\n",
      ">>> df.to_json(orient='records')\n",
      "'[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      ">>> pd.read_json(_, orient='records')\n",
      "  col 1 col 2\n",
      "0     a     b\n",
      "1     c     d\n",
      "\n",
      "Encoding with Table Schema\n",
      "\n",
      ">>> df.to_json(orient='table')\n",
      "'{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      "                        {\"name\": \"col 1\", \"type\": \"string\"},\n",
      "                        {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      "                \"primaryKey\": \"index\",\n",
      "                \"pandas_version\": \"0.20.0\"},\n",
      "    \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      "            {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n"
     ]
    }
   ],
   "source": [
    "np.info(pd.read_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
